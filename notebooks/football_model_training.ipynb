{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "151619b6",
   "metadata": {},
   "source": [
    "# ML Model Training and Persistence - Prototyping Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8403fe59",
   "metadata": {},
   "source": [
    "This notebook is part of **Story 2.1: ML Model Training and Persistence**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304dc787",
   "metadata": {},
   "source": [
    "Goals:\n",
    "- Load football match data from SQLite.\n",
    "- Preprocess features.\n",
    "- Train a classifier on match outcomes.\n",
    "- Save the trained model for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fd11e6",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. Setup and Data Loading with Feature Engineering (SQL-based)\n",
    "2. Data Exploration\n",
    "3. Data Preprocessing\n",
    "4. Model Training, Evaluation, and Persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949ceae6",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading with Feature Engineering (SQL-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c34d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "from pandas.io.sql import DatabaseError\n",
    "\n",
    "db_path = '../football.db'\n",
    "\n",
    "if not os.path.exists(db_path):\n",
    "    raise FileNotFoundError(f\"Database '{db_path}' not found. Run db_setup.py first.\")\n",
    "\n",
    "query = \"\"\"\n",
    "WITH\n",
    "  team_games AS (\n",
    "    SELECT\n",
    "      rowid, Date, HomeTeam AS team, 'home' as side,\n",
    "      CASE FTR WHEN 'H' THEN 3 WHEN 'D' THEN 1 ELSE 0 END AS points,\n",
    "      HS AS shots, HC AS corners, HF AS fouls,\n",
    "      FTHG AS goals_scored,\n",
    "      FTAG AS goals_conceded\n",
    "    FROM matches\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "      rowid, Date, AwayTeam AS team, 'away' as side,\n",
    "      CASE FTR WHEN 'A' THEN 3 WHEN 'D' THEN 1 ELSE 0 END AS points,\n",
    "      AS AS shots, AC AS corners, AF AS fouls,\n",
    "      FTAG AS goals_scored,\n",
    "      FTHG AS goals_conceded\n",
    "    FROM matches\n",
    "  ),\n",
    "  lagged AS (\n",
    "    SELECT\n",
    "      rowid, team, side, Date,\n",
    "      LAG(points, 1) OVER (PARTITION BY team ORDER BY Date) AS points_1,\n",
    "      LAG(points, 2) OVER (PARTITION BY team ORDER BY Date) AS points_2,\n",
    "      LAG(points, 3) OVER (PARTITION BY team ORDER BY Date) AS points_3,\n",
    "      LAG(points, 4) OVER (PARTITION BY team ORDER BY Date) AS points_4,\n",
    "      LAG(points, 5) OVER (PARTITION BY team ORDER BY Date) AS points_5,\n",
    "      LAG(points, 6) OVER (PARTITION BY team ORDER BY Date) AS points_6,\n",
    "      LAG(shots, 1) OVER (PARTITION BY team ORDER BY Date) AS shots_1,\n",
    "      LAG(shots, 2) OVER (PARTITION BY team ORDER BY Date) AS shots_2,\n",
    "      LAG(shots, 3) OVER (PARTITION BY team ORDER BY Date) AS shots_3,\n",
    "      LAG(shots, 4) OVER (PARTITION BY team ORDER BY Date) AS shots_4,\n",
    "      LAG(shots, 5) OVER (PARTITION BY team ORDER BY Date) AS shots_5,\n",
    "      LAG(shots, 6) OVER (PARTITION BY team ORDER BY Date) AS shots_6,\n",
    "      LAG(corners, 1) OVER (PARTITION BY team ORDER BY Date) AS corners_1,\n",
    "      LAG(corners, 2) OVER (PARTITION BY team ORDER BY Date) AS corners_2,\n",
    "      LAG(corners, 3) OVER (PARTITION BY team ORDER BY Date) AS corners_3,\n",
    "      LAG(corners, 4) OVER (PARTITION BY team ORDER BY Date) AS corners_4,\n",
    "      LAG(corners, 5) OVER (PARTITION BY team ORDER BY Date) AS corners_5,\n",
    "      LAG(corners, 6) OVER (PARTITION BY team ORDER BY Date) AS corners_6,\n",
    "      LAG(fouls, 1) OVER (PARTITION BY team ORDER BY Date) AS fouls_1,\n",
    "      LAG(fouls, 2) OVER (PARTITION BY team ORDER BY Date) AS fouls_2,\n",
    "      LAG(fouls, 3) OVER (PARTITION BY team ORDER BY Date) AS fouls_3,\n",
    "      LAG(fouls, 4) OVER (PARTITION BY team ORDER BY Date) AS fouls_4,\n",
    "      LAG(fouls, 5) OVER (PARTITION BY team ORDER BY Date) AS fouls_5,\n",
    "      LAG(fouls, 6) OVER (PARTITION BY team ORDER BY Date) AS fouls_6,\n",
    "      LAG(goals_scored, 1) OVER (PARTITION BY team ORDER BY Date) AS goals_scored_1,\n",
    "      LAG(goals_scored, 2) OVER (PARTITION BY team ORDER BY Date) AS goals_scored_2,\n",
    "      LAG(goals_scored, 3) OVER (PARTITION BY team ORDER BY Date) AS goals_scored_3,\n",
    "      LAG(goals_scored, 4) OVER (PARTITION BY team ORDER BY Date) AS goals_scored_4,\n",
    "      LAG(goals_scored, 5) OVER (PARTITION BY team ORDER BY Date) AS goals_scored_5,\n",
    "      LAG(goals_scored, 6) OVER (PARTITION BY team ORDER BY Date) AS goals_scored_6,\n",
    "      LAG(goals_conceded, 1) OVER (PARTITION BY team ORDER BY Date) AS goals_conceded_1,\n",
    "      LAG(goals_conceded, 2) OVER (PARTITION BY team ORDER BY Date) AS goals_conceded_2,\n",
    "      LAG(goals_conceded, 3) OVER (PARTITION BY team ORDER BY Date) AS goals_conceded_3,\n",
    "      LAG(goals_conceded, 4) OVER (PARTITION BY team ORDER BY Date) AS goals_conceded_4,\n",
    "      LAG(goals_conceded, 5) OVER (PARTITION BY team ORDER BY Date) AS goals_conceded_5,\n",
    "      LAG(goals_conceded, 6) OVER (PARTITION BY team ORDER BY Date) AS goals_conceded_6\n",
    "    FROM team_games\n",
    "  ),\n",
    "  game_features AS (\n",
    "    SELECT *,\n",
    "      (\n",
    "        COALESCE(points_1, 0) * 1.0 +\n",
    "        COALESCE(points_2, 0) * 0.8 +\n",
    "        COALESCE(points_3, 0) * 0.6 +\n",
    "        COALESCE(points_4, 0) * 0.4 +\n",
    "        COALESCE(points_5, 0) * 0.2 +\n",
    "        COALESCE(points_6, 0) * 0.1\n",
    "      ) / 9.3 * 10 AS form_score\n",
    "    FROM lagged\n",
    "  )\n",
    "SELECT\n",
    "  m.*,\n",
    "  h.form_score AS HomeTeam_FormScore,\n",
    "  a.form_score AS AwayTeam_FormScore,\n",
    "  h.shots_1, h.shots_2, h.shots_3, h.shots_4, h.shots_5, h.shots_6,\n",
    "  a.shots_1 AS a_shots_1, a.shots_2 AS a_shots_2, a.shots_3 AS a_shots_3,\n",
    "  a.shots_4 AS a_shots_4, a.shots_5 AS a_shots_5, a.shots_6 AS a_shots_6,\n",
    "  h.corners_1, h.corners_2, h.corners_3, h.corners_4, h.corners_5, h.corners_6,\n",
    "  a.corners_1 AS a_corners_1, a.corners_2 AS a_corners_2, a.corners_3 AS a_corners_3,\n",
    "  a.corners_4 AS a_corners_4, a.corners_5 AS a_corners_5, a.corners_6 AS a_corners_6,\n",
    "  h.fouls_1, h.fouls_2, h.fouls_3, h.fouls_4, h.fouls_5, h.fouls_6,\n",
    "  a.fouls_1 AS a_fouls_1, a.fouls_2 AS a_fouls_2, a.fouls_3 AS a_fouls_3,\n",
    "  a.fouls_4 AS a_fouls_4, a.fouls_5 AS a_fouls_5, a.fouls_6 AS a_fouls_6,\n",
    "  h.goals_scored_1, h.goals_scored_2, h.goals_scored_3, h.goals_scored_4, h.goals_scored_5, h.goals_scored_6,\n",
    "  a.goals_scored_1 AS a_goals_scored_1, a.goals_scored_2 AS a_goals_scored_2, a.goals_scored_3 AS a_goals_scored_3,\n",
    "  a.goals_scored_4 AS a_goals_scored_4, a.goals_scored_5 AS a_goals_scored_5, a.goals_scored_6 AS a_goals_scored_6,\n",
    "  h.goals_conceded_1, h.goals_conceded_2, h.goals_conceded_3, h.goals_conceded_4, h.goals_conceded_5, h.goals_conceded_6,\n",
    "  a.goals_conceded_1 AS a_goals_conceded_1, a.goals_conceded_2 AS a_goals_conceded_2, a.goals_conceded_3 AS a_goals_conceded_3,\n",
    "  a.goals_conceded_4 AS a_goals_conceded_4, a.goals_conceded_5 AS a_goals_conceded_5, a.goals_conceded_6 AS a_goals_conceded_6\n",
    "FROM matches m\n",
    "JOIN game_features h ON m.rowid = h.rowid AND h.side = 'home'\n",
    "JOIN game_features a ON m.rowid = a.rowid AND a.side = 'away'\n",
    "\"\"\"\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "try:\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    print(f\"✅ Loaded and processed {len(df)} rows from 'matches' table with form scores.\")\n",
    "    \n",
    "    # Calcul des moyennes en Python\n",
    "    df[\"HomeTeam_AvgShots\"] = df[[\"shots_1\", \"shots_2\", \"shots_3\", \"shots_4\", \"shots_5\", \"shots_6\"]].mean(axis=1)\n",
    "    df[\"AwayTeam_AvgShots\"] = df[[\"a_shots_1\", \"a_shots_2\", \"a_shots_3\", \"a_shots_4\", \"a_shots_5\", \"a_shots_6\"]].mean(axis=1)\n",
    "    \n",
    "    df[\"HomeTeam_AvgCorners\"] = df[[\"corners_1\", \"corners_2\", \"corners_3\", \"corners_4\", \"corners_5\", \"corners_6\"]].mean(axis=1)\n",
    "    df[\"AwayTeam_AvgCorners\"] = df[[\"a_corners_1\", \"a_corners_2\", \"a_corners_3\", \"a_corners_4\", \"a_corners_5\", \"a_corners_6\"]].mean(axis=1)\n",
    "    \n",
    "    df[\"HomeTeam_AvgFouls\"] = df[[\"fouls_1\", \"fouls_2\", \"fouls_3\", \"fouls_4\", \"fouls_5\", \"fouls_6\"]].mean(axis=1)\n",
    "    df[\"AwayTeam_AvgFouls\"] = df[[\"a_fouls_1\", \"a_fouls_2\", \"a_fouls_3\", \"a_fouls_4\", \"a_fouls_5\", \"a_fouls_6\"]].mean(axis=1)\n",
    "    \n",
    "    # Nouvelles moyennes de buts\n",
    "    df[\"HomeTeam_AvgGoalsScored\"] = df[[\"goals_scored_1\", \"goals_scored_2\", \"goals_scored_3\", \"goals_scored_4\", \"goals_scored_5\", \"goals_scored_6\"]].mean(axis=1)\n",
    "    df[\"AwayTeam_AvgGoalsScored\"] = df[[\"a_goals_scored_1\", \"a_goals_scored_2\", \"a_goals_scored_3\", \"a_goals_scored_4\", \"a_goals_scored_5\", \"a_goals_scored_6\"]].mean(axis=1)\n",
    "    \n",
    "    df[\"HomeTeam_AvgGoalsConceded\"] = df[[\"goals_conceded_1\", \"goals_conceded_2\", \"goals_conceded_3\", \"goals_conceded_4\", \"goals_conceded_5\", \"goals_conceded_6\"]].mean(axis=1)\n",
    "    df[\"AwayTeam_AvgGoalsConceded\"] = df[[\"a_goals_conceded_1\", \"a_goals_conceded_2\", \"a_goals_conceded_3\", \"a_goals_conceded_4\", \"a_goals_conceded_5\", \"a_goals_conceded_6\"]].mean(axis=1)\n",
    "    \n",
    "except DatabaseError as e:\n",
    "    df = pd.DataFrame()\n",
    "    print(f\"❌ Error loading data: {e}\")\n",
    "finally:\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7fd4ed",
   "metadata": {},
   "source": [
    "## 2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e47564",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.empty:\n",
    "    print(\"❌ DataFrame is empty. Cannot proceed.\")\n",
    "else:\n",
    "    display(df.head())\n",
    "    print(\"\\nDataFrame Info:\")\n",
    "    display(df.info())\n",
    "    print(\"\\nData Description:\")\n",
    "    display(df.describe(include='all'))\n",
    "    \n",
    "    # Vérification des nouvelles caractéristiques de buts\n",
    "    print(\"\\n📊 Nouvelles caractéristiques de buts:\")\n",
    "    goals_features = ['HomeTeam_AvgGoalsScored', 'AwayTeam_AvgGoalsScored', 'HomeTeam_AvgGoalsConceded', 'AwayTeam_AvgGoalsConceded']\n",
    "    for feature in goals_features:\n",
    "        if feature in df.columns:\n",
    "            print(f\"{feature}: min={df[feature].min():.2f}, max={df[feature].max():.2f}, mean={df[feature].mean():.2f}\")\n",
    "        else:\n",
    "            print(f\"❌ {feature} not found in DataFrame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e107ef47",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b5f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "categorical_features = ['HomeTeam', 'AwayTeam']\n",
    "# Mise à jour des caractéristiques numériques - remplacement de HS et AS par les moyennes de buts\n",
    "numerical_features = [\n",
    "    'HomeTeam_FormScore', 'AwayTeam_FormScore',\n",
    "    'HomeTeam_AvgShots', 'AwayTeam_AvgShots',\n",
    "    'HomeTeam_AvgCorners', 'AwayTeam_AvgCorners',\n",
    "    'HomeTeam_AvgFouls', 'AwayTeam_AvgFouls',\n",
    "    'HomeTeam_AvgGoalsScored', 'AwayTeam_AvgGoalsScored',\n",
    "    'HomeTeam_AvgGoalsConceded', 'AwayTeam_AvgGoalsConceded'\n",
    "]\n",
    "\n",
    "for col in numerical_features:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    else:\n",
    "        print(f\"⚠️ Warning: {col} not found in DataFrame\")\n",
    "\n",
    "essential_cols = [col for col in numerical_features if col in df.columns] + categorical_features + ['FTR']\n",
    "df_processed = df.dropna(subset=essential_cols)\n",
    "\n",
    "# Gestion des valeurs manquantes pour les nouvelles caractéristiques\n",
    "goals_features = ['HomeTeam_AvgGoalsScored', 'AwayTeam_AvgGoalsScored', 'HomeTeam_AvgGoalsConceded', 'AwayTeam_AvgGoalsConceded']\n",
    "for col in goals_features:\n",
    "    if col in df_processed.columns:\n",
    "        # Remplacer les NaN par la moyenne globale\n",
    "        df_processed[col] = df_processed[col].fillna(df_processed[col].mean())\n",
    "        print(f\"✅ Handled missing values for {col}\")\n",
    "\n",
    "available_numerical_features = [col for col in numerical_features if col in df_processed.columns]\n",
    "features = categorical_features + available_numerical_features\n",
    "X = df_processed[features]\n",
    "y = df_processed['FTR']\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_pipeline, available_numerical_features),\n",
    "    ('cat', categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"✅ Data preprocessing complete. Training with {len(X_train)} samples.\")\n",
    "print(f\"📊 Using features: {features}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081858a5",
   "metadata": {},
   "source": [
    "## 4. Model Training, Evaluation, and Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db7eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"🎯 Model Accuracy: {accuracy:.2f}\")\n",
    "print(f\"\\n📊 Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Validation de l'absence de fuite de données\n",
    "print(\"\\n🔍 Validation - Caractéristiques utilisées:\")\n",
    "feature_names = (categorical_features + available_numerical_features)\n",
    "for feature in feature_names:\n",
    "    if 'HS' in feature or 'AS' in feature:\n",
    "        print(f\"⚠️ ATTENTION: {feature} pourrait causer une fuite de données\")\n",
    "    else:\n",
    "        print(f\"✅ {feature} - OK (données historiques)\")\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "model_path = 'models/prediction_model.pkl'\n",
    "joblib.dump(model_pipeline, model_path)\n",
    "print(f\"\\n💾 Model saved to {model_path}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}