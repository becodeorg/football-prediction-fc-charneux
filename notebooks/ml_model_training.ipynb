{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model Training and Persistence - Prototyping Notebook\n",
    "\n",
    "This notebook is part of **Story 2.1: ML Model Training and Persistence**.\n",
    "\n",
    "Goals:\n",
    "- Load football match data from SQLite.\n",
    "- Preprocess features.\n",
    "- Train a classifier on match outcomes.\n",
    "- Save the trained model for inference.\n",
    "\n",
    "Steps:\n",
    "1. Setup and Data Loading\n",
    "2. Data Exploration\n",
    "3. Data Preprocessing\n",
    "4. Model Training, Evaluation, and Persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 1774 rows from 'matches' table\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "from pandas.io.sql import DatabaseError\n",
    "\n",
    "# Path to database\n",
    "db_path = '../football.db'\n",
    "\n",
    "if not os.path.exists(db_path):\n",
    "    raise FileNotFoundError(f\"Database '{db_path}' not found. Run db_setup.py first.\")\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "try:\n",
    "    df_raw = pd.read_sql_query(\"SELECT * FROM matches\", conn)\n",
    "    print(f\"✅ Loaded {len(df_raw)} rows from 'matches' table\")\n",
    "except DatabaseError as e:\n",
    "    df_raw = pd.DataFrame()\n",
    "    print(f\"❌ Error loading data: {e}\")\n",
    "finally:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing step 1: add column 'Season' (for time series training-testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_season(df):\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    def get_season(date):\n",
    "        if pd.Timestamp('2024-07-26') <= date <= pd.Timestamp('2025-05-29'):\n",
    "            return '2024/2025'\n",
    "        elif pd.Timestamp('2023-07-28') <= date <= pd.Timestamp('2024-06-02'):\n",
    "            return '2023/2024'\n",
    "        elif pd.Timestamp('2022-07-22') <= date <= pd.Timestamp('2023-04-23'):\n",
    "            return '2022/2023'\n",
    "        elif pd.Timestamp('2021-07-23') <= date <= pd.Timestamp('2022-04-10'):\n",
    "            return '2021/2022'\n",
    "        elif pd.Timestamp('2020-08-08') <= date <= pd.Timestamp('2021-04-18'):\n",
    "            return '2020/2021'\n",
    "        else:\n",
    "            return '2019/2020'\n",
    "\n",
    "    df['Season'] = df['Date'].apply(get_season)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing step 2: add rolling goal-related overall performance columns(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_rolling_perf(df, rolling_window):\n",
    "    # Copy and sort dataset chronologically\n",
    "    df_raw = df.copy()\n",
    "    df_raw = df_raw.sort_values('Date').reset_index(drop=True)\n",
    "    df_raw['rowid'] = df_raw.index  # Unique ID to merge later\n",
    "\n",
    "    # Home team features\n",
    "    home_df = df_raw[['rowid', 'Date', 'HomeTeam', 'FTR', 'HS', 'HST', 'HC', 'HF', 'HY', 'HR', 'FTHG', 'FTAG']].copy()\n",
    "    home_df['team'] = home_df['HomeTeam']\n",
    "    home_df['side'] = 'home'\n",
    "    home_df['points'] = home_df['FTR'].map({'H': 3, 'D': 1, 'A': 0})\n",
    "    home_df = home_df.rename(columns={\n",
    "        'HS': 'shots', 'HST': 'shots_on_target',\n",
    "        'HC': 'corners', 'HF': 'fouls',\n",
    "        'HY': 'yellow_cards', 'HR': 'red_cards',\n",
    "        'FTHG': 'goals_scored', 'FTAG': 'goals_conceded'\n",
    "    })\n",
    "\n",
    "    # Away team features\n",
    "    away_df = df_raw[['rowid', 'Date', 'AwayTeam', 'FTR', 'AS', 'AST', 'AC', 'AF', 'AY', 'AR', 'FTAG', 'FTHG']].copy()\n",
    "    away_df['team'] = away_df['AwayTeam']\n",
    "    away_df['side'] = 'away'\n",
    "    away_df['points'] = away_df['FTR'].map({'A': 3, 'D': 1, 'H': 0})\n",
    "    away_df = away_df.rename(columns={\n",
    "        'AS': 'shots', 'AST': 'shots_on_target',\n",
    "        'AC': 'corners', 'AF': 'fouls',\n",
    "        'AY': 'yellow_cards', 'AR': 'red_cards',\n",
    "        'FTAG': 'goals_scored', 'FTHG': 'goals_conceded'\n",
    "    })\n",
    "\n",
    "    # Combine and sort\n",
    "    team_games = pd.concat([\n",
    "        home_df[['rowid', 'Date', 'team', 'side', 'points', 'shots', 'shots_on_target',\n",
    "                 'corners', 'fouls', 'yellow_cards', 'red_cards', 'goals_scored', 'goals_conceded']],\n",
    "        away_df[['rowid', 'Date', 'team', 'side', 'points', 'shots', 'shots_on_target',\n",
    "                 'corners', 'fouls', 'yellow_cards', 'red_cards', 'goals_scored', 'goals_conceded']]\n",
    "    ])\n",
    "    team_games = team_games.sort_values(by=['team', 'Date'])\n",
    "\n",
    "    # Weight setup\n",
    "    weights = np.arange(1, rolling_window + 1)\n",
    "    weights = weights / weights.sum()\n",
    "\n",
    "    def weighted_avg(series, weights_array):\n",
    "        w = weights_array[-len(series):]\n",
    "        return np.dot(series, w)\n",
    "\n",
    "    # Form Score (weighted Points)\n",
    "    team_games['form_score'] = (\n",
    "        team_games.groupby('team')['points']\n",
    "        .apply(lambda x: x.shift(1).rolling(window=rolling_window, min_periods=rolling_window)\n",
    "               .apply(lambda y: weighted_avg(y, weights), raw=True))\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    # Other stats (weighted Averages)\n",
    "    for col in ['shots', 'shots_on_target', 'corners', 'fouls',\n",
    "                'yellow_cards', 'red_cards', 'goals_scored', 'goals_conceded']:\n",
    "        team_games[f'avg_{col}'] = (\n",
    "            team_games.groupby('team')[col]\n",
    "            .apply(lambda x: x.shift(1).rolling(window=rolling_window, min_periods=rolling_window)\n",
    "                   .apply(lambda y: weighted_avg(y, weights), raw=True))\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "\n",
    "    # Split home/away features\n",
    "    home_features = team_games[team_games['side'] == 'home'].copy()\n",
    "    away_features = team_games[team_games['side'] == 'away'].copy()\n",
    "\n",
    "    # Merge back to original data\n",
    "    df_enriched = df_raw.merge(home_features[[\n",
    "        'rowid', 'form_score', 'avg_shots', 'avg_shots_on_target', 'avg_corners',\n",
    "        'avg_fouls', 'avg_yellow_cards', 'avg_red_cards',\n",
    "        'avg_goals_scored', 'avg_goals_conceded'\n",
    "    ]], on='rowid', how='left').rename(columns={\n",
    "        'form_score': 'HomeTeam_FormScore',\n",
    "        'avg_shots': 'HomeTeam_AvgShots',\n",
    "        'avg_shots_on_target': 'HomeTeam_AvgShotsOnTarget',\n",
    "        'avg_corners': 'HomeTeam_AvgCorners',\n",
    "        'avg_fouls': 'HomeTeam_AvgFouls',\n",
    "        'avg_yellow_cards': 'HomeTeam_AvgYellowCards',\n",
    "        'avg_red_cards': 'HomeTeam_AvgRedCards',\n",
    "        'avg_goals_scored': 'HomeTeam_AvgGoalsScored',\n",
    "        'avg_goals_conceded': 'HomeTeam_AvgGoalsConceded'\n",
    "    })\n",
    "\n",
    "    df_enriched = df_enriched.merge(away_features[[\n",
    "        'rowid', 'form_score', 'avg_shots', 'avg_shots_on_target', 'avg_corners',\n",
    "        'avg_fouls', 'avg_yellow_cards', 'avg_red_cards',\n",
    "        'avg_goals_scored', 'avg_goals_conceded'\n",
    "    ]], on='rowid', how='left').rename(columns={\n",
    "        'form_score': 'AwayTeam_FormScore',\n",
    "        'avg_shots': 'AwayTeam_AvgShots',\n",
    "        'avg_shots_on_target': 'AwayTeam_AvgShotsOnTarget',\n",
    "        'avg_corners': 'AwayTeam_AvgCorners',\n",
    "        'avg_fouls': 'AwayTeam_AvgFouls',\n",
    "        'avg_yellow_cards': 'AwayTeam_AvgYellowCards',\n",
    "        'avg_red_cards': 'AwayTeam_AvgRedCards',\n",
    "        'avg_goals_scored': 'AwayTeam_AvgGoalsScored',\n",
    "        'avg_goals_conceded': 'AwayTeam_AvgGoalsConceded'\n",
    "    })\n",
    "\n",
    "    return df_enriched\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try single conventional ML model in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Select the best model from multiple combinations of features & model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "\n",
    "feature_groups = [['B365H', 'B365D', 'B365A'], # odds, mannually chosed\n",
    "                     ['HomeTeam_FormScore', 'AwayTeam_FormScore'],\n",
    "                     ['HomeTeam_AvgShots', 'AwayTeam_AvgShots'],\n",
    "                     ['HomeTeam_AvgShotsOnTarget', 'AwayTeam_AvgShotsOnTarget'],\n",
    "                     ['HomeTeam_AvgCorners', 'AwayTeam_AvgCorners'],\n",
    "                     ['HomeTeam_AvgFouls', 'AwayTeam_AvgFouls'],\n",
    "                     ['HomeTeam_AvgYellowCards', 'AwayTeam_AvgYellowCards'],\n",
    "                     ['HomeTeam_AvgRedCards', 'AwayTeam_AvgRedCards'],\n",
    "                     ['HomeTeam_AvgGoalsScored', 'AwayTeam_AvgGoalsScored'],\n",
    "                     ['HomeTeam_AvgGoalsConceded', 'AwayTeam_AvgGoalsConceded']]\n",
    "\n",
    "# Loop combination of features and model to find the best model:\n",
    "acc_ultra_max = 0\n",
    "model_ultra_max = \"Init\"\n",
    "features_ultra_max = []\n",
    "\n",
    "for r in range(1, len(feature_groups) + 1):\n",
    "    for combo in itertools.combinations(feature_groups, r):\n",
    "        # Prepare selected features\n",
    "        selected_features = ['HomeTeam', 'AwayTeam'] + [feature for group in combo for feature in group]\n",
    "        print(f\"📂 Selected features: {selected_features}\")\n",
    "\n",
    "        # Add 'Season' and rolling performance cols to dataset, drop null values\n",
    "        df = add_season(df_raw)\n",
    "        df = add_rolling_perf(df, rolling_window=10)\n",
    "        df = df[selected_features + ['FTR'] +['Season']].dropna() #dropna is optional, if not, will be imputed by mean in later sklearn pipelines\n",
    "\n",
    "        # Prepare train and test subsets\n",
    "        train_df = df[df['Season'] != '2024/2025']\n",
    "        test_df = df[df['Season'] == '2024/2025']\n",
    "        X_train = train_df[selected_features]\n",
    "        y_train = train_df['FTR']\n",
    "        X_test = test_df[selected_features]\n",
    "        y_test = test_df['FTR']\n",
    "\n",
    "        # Make clear cat and num features in X for later sklearn pipeline\n",
    "        categorical_features = ['HomeTeam', 'AwayTeam']\n",
    "        numerical_features = [col for col in X_train.columns if col not in categorical_features]\n",
    "\n",
    "        # Prepare sklearn pipelines for different models.\n",
    "        # Note that most models support one-hot, for models do not supporting sparse matrix (HistGradientBoosting, NaiveBayes, QDA), use ordinal encoding instead\n",
    "        # Note that imputer is useless if previous already dropna. Scaler is optional, we just applied it here.\n",
    "        numeric_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        # optional: PCA (proven to be useless, discard :( )\n",
    "        # numeric_pipeline = numeric_pipeline = Pipeline([\n",
    "        #     ('imputer', SimpleImputer(strategy='mean')),\n",
    "        #     ('scaler', StandardScaler()),\n",
    "        #     ('pca', PCA(n_components=0.95))\n",
    "        # ])\n",
    "        categorical_pipeline1 = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "        categorical_pipeline2 = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "            ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "        ])\n",
    "        preprocessor1 = ColumnTransformer([\n",
    "            ('num', numeric_pipeline, numerical_features),\n",
    "            ('cat', categorical_pipeline1, categorical_features)\n",
    "        ])\n",
    "        preprocessor2 = ColumnTransformer([\n",
    "            ('num', numeric_pipeline, numerical_features),\n",
    "            ('cat', categorical_pipeline2, categorical_features)\n",
    "        ])\n",
    "        models_and_preprocessors = {\n",
    "            \"RandomForest\": [RandomForestClassifier(random_state=42), preprocessor1],\n",
    "            \"LogisticRegression\": [LogisticRegression(max_iter=1000, random_state=42), preprocessor1],\n",
    "            \"PassiveAggressiveClassifier\": [PassiveAggressiveClassifier(max_iter=1000, random_state=42), preprocessor1],\n",
    "            \"RidgeClassifier\": [RidgeClassifier(max_iter=1000), preprocessor1],\n",
    "            \"KNN\": [KNeighborsClassifier(), preprocessor1],\n",
    "            \"SVC\": [SVC(random_state=42), preprocessor1],\n",
    "            \"DecisionTree\": [DecisionTreeClassifier(random_state=42), preprocessor1],\n",
    "            \"GradientBoosting\": [GradientBoostingClassifier(random_state=42), preprocessor1],\n",
    "            \"HistGradientBoosting\": [HistGradientBoostingClassifier(random_state=42), preprocessor2],\n",
    "            \"AdaBoost\": [AdaBoostClassifier(random_state=42), preprocessor1],\n",
    "            \"ExtraTrees\": [ExtraTreesClassifier(random_state=42), preprocessor1],\n",
    "            \"NaiveBayes\": [GaussianNB(), preprocessor2],\n",
    "            \"MLP\": [MLPClassifier(max_iter=1000, random_state=42), preprocessor1],\n",
    "            \"QDA\": [QuadraticDiscriminantAnalysis(), preprocessor2],\n",
    "            \"LDA\": [LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto'), preprocessor2]\n",
    "        }\n",
    "\n",
    "        # Loop to train in different models and display selected features and accuracy\n",
    "        acc_max = 0\n",
    "        model_max = \"Init\"\n",
    "        for name, model_and_proprocessor in models_and_preprocessors.items():\n",
    "            model_pipeline = Pipeline([\n",
    "                ('preprocess', model_and_proprocessor[1]),\n",
    "                ('classifier', model_and_proprocessor[0])\n",
    "            ])\n",
    "            model_pipeline.fit(X_train, y_train)\n",
    "            y_pred = model_pipeline.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            print(f\"🎯 {name} Accuracy: {acc:.4f}\")\n",
    "            if acc > acc_max:\n",
    "                acc_max = acc\n",
    "                model_max = name\n",
    "        \n",
    "        # Update the best model in this selected features\n",
    "        if acc_max > acc_ultra_max:\n",
    "            acc_ultra_max = acc_max\n",
    "            model_ultra_max = model_max\n",
    "            features_ultra_max = selected_features\n",
    "        \n",
    "    print(f\"The best model until now is {model_ultra_max}.\\nThe accuracy is {acc_ultra_max}.\\nUsed features: {features_ultra_max}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is **LDA** with **05404** accuracy using the feature combination: ['HomeTeam', 'AwayTeam', 'B365H', 'B365D', 'B365A', 'HomeTeam_FormScore', 'AwayTeam_FormScore', 'HomeTeam_AvgRedCards', 'AwayTeam_AvgRedCards', 'HomeTeam_AvgGoalsScored', 'AwayTeam_AvgGoalsScored'].\n",
    "\n",
    "The best model without betting features is **RidgeClassifier** with **0.5292** accuracy using the feature combination: ['HomeTeam', 'AwayTeam', 'HomeTeam_FormScore', 'AwayTeam_FormScore', 'HomeTeam_AvgShots', 'AwayTeam_AvgShots', 'HomeTeam_AvgFouls', 'AwayTeam_AvgFouls', 'HomeTeam_AvgRedCards', 'AwayTeam_AvgRedCards']\n",
    "\n",
    "See **sklearn_model_acc.txt** the records of all models' accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try mixed model in H2O AutoML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from h2o.automl import get_leaderboard\n",
    "\n",
    "# Initiate h2o and input the train and test set (note that h2o will handel cross-validation automately in train set)\n",
    "selected_features = ['HomeTeam', 'AwayTeam'] + [item for sublist in feature_groups for item in sublist]\n",
    "df = add_season(df_raw)\n",
    "df = add_rolling_perf(df, rolling_window=10)\n",
    "df = df[selected_features + ['FTR'] +['Season']].dropna()\n",
    "train_df = df[df['Season'] != '2024/2025']\n",
    "test_df = df[df['Season'] == '2024/2025']\n",
    "X_train = train_df[selected_features]\n",
    "y_train = train_df['FTR']\n",
    "X_test = test_df[selected_features]\n",
    "y_test = test_df['FTR']\n",
    "\n",
    "h2o.init()\n",
    "train_h2o = h2o.H2OFrame(train_df)\n",
    "test_h2o = h2o.H2OFrame(test_df)\n",
    "\n",
    "# Ensure H2o know the target is a classification problem\n",
    "target_col = 'FTR'\n",
    "train_h2o[target_col] = train_h2o[target_col].asfactor()\n",
    "test_h2o[target_col] = test_h2o[target_col].asfactor()\n",
    "\n",
    "# Ensure H2o know the categorial cols in preictor variables is categorial\n",
    "for col in ['HomeTeam', 'AwayTeam']:\n",
    "    train_h2o[col] = train_h2o[col].asfactor()\n",
    "    test_h2o[col] = test_h2o[col].asfactor()\n",
    "\n",
    "# Set the param for automl and train it\n",
    "aml = H2OAutoML(\n",
    "    # max_models=50, # try maximum 50 models\n",
    "    max_runtime_secs=60, # limit total runtime to 60 seconds\n",
    "    balance_classes=True, # upsample the minority classes - \"Draw\"\n",
    "    sort_metric='logloss', # good for multi-class classification\n",
    "    nfolds=5, # use 5-fold cross-validation\n",
    "    stopping_metric='logloss', # early stopping based on log loss\n",
    "    stopping_rounds=30, # early stop after 30 rounds of no improvement\n",
    "    seed=42 # random state 42\n",
    ")\n",
    "aml.train(x=[col for col in train_h2o.columns if col != target_col], y=target_col, training_frame=train_h2o)\n",
    "\n",
    "# Get the best mixed model from the leaderboard\n",
    "lb = get_leaderboard(aml, extra_columns='ALL')\n",
    "top_models = lb.head(rows=1) # only need the top 1 model here\n",
    "model_id = top_models.as_data_frame().iloc[0]['model_id']\n",
    "model = h2o.get_model(model_id)\n",
    "\n",
    "# Show model and train-val info\n",
    "if model.algo == \"stackedensemble\":\n",
    "    print(f\"🖥️ {model.metalearner()}\")\n",
    "else:\n",
    "    print(f\"🖥️ {model.algo}\")\n",
    "    print(\"Info:\", model._model_json['output'])\n",
    "            \n",
    "# Display accuracy\n",
    "preds = model.predict(test_h2o).as_data_frame()['predict']\n",
    "true = test_h2o[y.name].as_data_frame()[y.name]\n",
    "acc = accuracy_score(true, preds)\n",
    "print(f\"🎯 Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try NN in Pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
